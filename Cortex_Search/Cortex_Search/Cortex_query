-----------------------------------------------------------------------------------------
**********************************CORTEX SEARCH******************************************
-----------------------------------------------------------------------------------------

-- -----------------------Listing files in the specified stage--------------------------
LIST @CORTEX_SEARCH_STAGE;

------------------------------Creating the PDF Text Chunking Function---------------------

CREATE OR REPLACE FUNCTION pdf_text_chunker(file_url STRING)
RETURNS TABLE (chunk VARCHAR)
LANGUAGE PYTHON
RUNTIME_VERSION = '3.9'
HANDLER = 'pdf_text_chunker'
PACKAGES = ('snowflake-snowpark-python', 'PyPDF2', 'langchain')
AS
$$
from snowflake.snowpark import types as T
from langchain.text_splitter import RecursiveCharacterTextSplitter
from snowflake.snowpark.files import SnowflakeFile
import PyPDF2, io
import logging

# Define the PDF text chunker class
class pdf_text_chunker:
    
    def read_pdf(self, file_url: str) -> str:
        logger = logging.getLogger("udf_logger")
        logger.info(f"Opening file {file_url}")
        
        # Open and read the PDF from the Snowflake stage
        with SnowflakeFile.open(file_url, 'rb') as f:
            buffer = io.BytesIO(f.read())
        
        # Use PyPDF2 to extract text from the PDF
        reader = PyPDF2.PdfReader(buffer)
        text = ""
        for page in reader.pages:
            try:
                text += page.extract_text().replace('\n', ' ').replace('\0', ' ')
            except:
                text = "Unable to Extract"
                logger.warning(f"Unable to extract from file {file_url}, page {page}")
        
        return text

    def process(self, file_url: str):
        # Extract text from the PDF file
        text = self.read_pdf(file_url)
        
        # Split the text into chunks using RecursiveCharacterTextSplitter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=4000,  # Adjust chunk size as needed
            chunk_overlap=400,  # Some overlap for better context
            length_function=len
        )
        
        # Split the extracted text into chunks
        chunks = text_splitter.split_text(text)
        
        # Yield the chunks one by one
        for chunk in chunks:
            yield (chunk,)

$$;

---------------------Creating the Chunk Table for PDF Data---------------------------------------------

CREATE OR REPLACE TABLE CHUNK_CORTEX_PDF (
    RELATIVE_PATH VARCHAR(16777216), 
    SIZE NUMBER(38, 0), 
    FILE_URL VARCHAR(16777216), 
    SCOPED_FILE_URL VARCHAR(16777216),
    CHUNK VARCHAR(16777216), 
    CHUNK_VEC VECTOR(FLOAT, 768) 
);

select * from CHUNK_CORTEX_PDF;


----------------------------Inserting Data into the Chunk Table----------------------------------------

INSERT INTO CHUNK_CORTEX_PDF (relative_path, size, file_url, scoped_file_url, chunk, chunk_vec)
    SELECT
        relative_path,  
        size,           
        file_url,       
        build_scoped_file_url(@CORTEX_SEARCH_STAGE, relative_path) AS scoped_file_url, 
        func.chunk AS chunk,  -- Chunk from the pdf_text_chunker function
        SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', func.chunk) AS chunk_vec 
    FROM
        DIRECTORY(@CORTEX_SEARCH_STAGE) AS dir,  
        TABLE(pdf_text_chunker(build_scoped_file_url(@CORTEX_SEARCH_STAGE, dir.relative_path))) AS func;  


-----------------------------Creating the Cortex Search Service----------------------------------


CREATE OR REPLACE CORTEX SEARCH SERVICE CORTEX_TOKEN_DB.CORTEX_TOKEN_SCHEMA.PDF_CHUNK_SERVICE
  ON CHUNK
  ATTRIBUTES RELATIVE_PATH, FILE_URL, SCOPED_FILE_URL, CHUNK
  WAREHOUSE = compute_wh
  TARGET_LAG = '1 hour'
  AS (
    SELECT * FROM CHUNK_CORTEX_PDF
  );

SELECT * FROM CHUNK_CORTEX_PDF
----------------------------Testing the Search Service Without Stored Procedure-----------------------

SELECT PARSE_JSON(
  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(
      'CORTEX_TOKEN_DB.CORTEX_TOKEN_SCHEMA.PDF_CHUNK_SERVICE',
      '{
         "query": "Explain Oncology",
         "columns":[
            "CHUNK",
            "RELATIVE_PATH",
            "FILE_URL"
         ],
         "limit": 5
      }'
  )
)['results'] AS results;

-----------------------------------Creating the Cortex Search Procedure-------------------------------------

CREATE OR REPLACE PROCEDURE cortex_search_procedure(
    search_query STRING,              
    filter_column STRING,              
    filter_value STRING,               
    result_limit INT                  
)
RETURNS VARIANT
LANGUAGE SQL
EXECUTE AS CALLER
AS
$$
    DECLARE
        json_query STRING;
    BEGIN
        -- Construct the JSON payload without explicit casting
        json_query := OBJECT_CONSTRUCT(
              'query', search_query,
              'columns', ARRAY_CONSTRUCT('CHUNK', 'RELATIVE_PATH', 'FILE_URL'),
              'filter', OBJECT_CONSTRUCT('@eq', OBJECT_CONSTRUCT(filter_column, filter_value)),
              'limit', result_limit
        );

        -- Call SEARCH_PREVIEW function
        RETURN PARSE_JSON(
            SNOWFLAKE.CORTEX.SEARCH_PREVIEW(
                'CORTEX_TOKEN_DB.CORTEX_TOKEN_SCHEMA.PDF_CHUNK_SERVICE',
                json_query
            )
        )['results'];
    END;
$$;

------------------------------------Testing the Search Service With Stored Procedure------------------------------

CALL cortex_search_procedure('Explain Oncology', 'RELATIVE_PATH', 'Cardiology_Comprehensive_Overview.pdf', 5);